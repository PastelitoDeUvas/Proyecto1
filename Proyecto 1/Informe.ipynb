{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de los datos 2D\n",
    "data_2d = pd.read_csv(\"data_2d.csv\")\n",
    "\n",
    "# Mostrar los primeros 5 registros\n",
    "print(\"Datos 2D:\")\n",
    "print(data_2d.head())\n",
    "\n",
    "\n",
    "# Lectura de los datos 3D\n",
    "data_3d = pd.read_csv(\"data_3d.csv\")\n",
    "\n",
    "# Mostrar los primeros 5 registros\n",
    "print(\"Datos 3D:\")\n",
    "print(data_3d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estudio estadistico de los datos 2D\n",
    "print(\"Estudio estadistico de los datos 2D:\")\n",
    "print(data_2d.describe())\n",
    "\n",
    "# Estudio estadistico de los datos 3D\n",
    "print(\"Estudio estadistico de los datos 3D:\")\n",
    "print(data_3d.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de los datos 2D\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data_2d[\"x\"], data_2d[\"y\"], s=50)\n",
    "plt.title(\"Datos 2D\")\n",
    "# Gráfica de los datos 3D\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data_3d[\"x\"], data_3d[\"y\"], data_3d[\"z\"], s=50)\n",
    "ax.set_title(\"Datos 3D\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos\n",
    "scaler = StandardScaler()\n",
    "data_2d = scaler.fit_transform(data_2d)\n",
    "data_3d = scaler.fit_transform(data_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para K-Means con distintas métricas de distancia\n",
    "def euclidean_distance(A, B):\n",
    "    return np.linalg.norm(A - B, axis=1)\n",
    "\n",
    "def manhattan_distance(A, B):\n",
    "    return np.sum(np.abs(A - B), axis=1)\n",
    "\n",
    "def chebyshev_distance(A, B):\n",
    "    return np.max(np.abs(A - B), axis=1)\n",
    "\n",
    "distance_metrics = {\n",
    "    \"Euclidiana\": euclidean_distance,\n",
    "    \"Manhattan\": manhattan_distance,\n",
    "    \"Chebyshev\": chebyshev_distance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_centroids(X, k):\n",
    "    np.random.seed(41342)\n",
    "    centroids = [X[np.random.randint(len(X))]]  # Primer centroide aleatorio\n",
    "    for _ in range(1, k):\n",
    "        distances = np.array([min([np.linalg.norm(x - c) for c in centroids]) for x in X])\n",
    "        probabilities = distances / distances.sum()\n",
    "        new_centroid = X[np.random.choice(len(X), p=probabilities)]\n",
    "        centroids.append(new_centroid)\n",
    "    return np.array(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(X, centroids, metric_func):\n",
    "    distances = np.array([metric_func(X, centroid) for centroid in centroids])\n",
    "    return np.argmin(distances, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_centroids(X, labels, k):\n",
    "    new_centroids = []\n",
    "    for i in range(k):\n",
    "        cluster_points = X[labels == i]\n",
    "        if len(cluster_points) > 0:\n",
    "            new_centroids.append(cluster_points.mean(axis=0))\n",
    "        else:\n",
    "            farthest_point = X[np.argmax([np.min([np.linalg.norm(x - c) for c in new_centroids]) for x in X])]\n",
    "            new_centroids.append(farthest_point)\n",
    "    return np.array(new_centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inertia(X, centroids, labels):\n",
    "    inertia = 0\n",
    "    labels = np.array(labels)\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        cluster_points = X[labels == i]\n",
    "        inertia += np.sum((cluster_points - centroid) ** 2)\n",
    "    return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k, metric_func, max_iters=100, tol=1e-4):\n",
    "    centroids = initialize_centroids(X, k)\n",
    "    for _ in range(max_iters):\n",
    "        labels = assign_clusters(X, centroids, metric_func)\n",
    "        new_centroids = update_centroids(X, labels, k)\n",
    "        if np.mean(np.linalg.norm(new_centroids - centroids, axis=1)) < tol:\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    inertia = compute_inertia(X, centroids, labels)\n",
    "    return centroids, labels, inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de clusters\n",
    "k = 5\n",
    "\n",
    "# Aplicar k-means con cada métrica\n",
    "for metric_name, metric_func in distance_metrics.items():\n",
    "    print(f\"Métrica: {metric_name}\")\n",
    "    centroids_2d, labels_2d, inertia_2d = kmeans(data_2d, k, metric_func)\n",
    "    plt.scatter(data_2d[:, 0], data_2d[:, 1], c=labels_2d, cmap='viridis', alpha=0.6)\n",
    "    plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], c='red', marker='x', s=100)\n",
    "    plt.title(f\"K-Means - 2D ({metric_name})\\nInercia: {inertia_2d:.2f}\")\n",
    "    plt.show()\n",
    "\n",
    "    centroids_3d, labels_3d, inertia_3d = kmeans(data_3d, k, metric_func)\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(data_3d[:, 0], data_3d[:, 1], data_3d[:, 2], c=labels_3d, cmap='viridis', alpha=0.6)\n",
    "    ax.scatter(centroids_3d[:, 0], centroids_3d[:, 1], centroids_3d[:, 2], c='red', marker='x', s=100)\n",
    "    ax.set_title(f\"K-Means - 3D ({metric_name})\\nInercia: {inertia_3d:.2f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impacto de la Métrica de Distancia en la Asignación de Clusters con K-Means\n",
    "\n",
    "Resultados\n",
    "Se probó el algoritmo K-Means con distintas métricas de distancia (Euclidiana, Manhattan y Chebyshev) y con diferentes semillas de inicialización. No se observaron cambios significativos en la asignación de clusters ni en la inercia final.\n",
    "\n",
    "Impacto de la Métrica de Distancia\n",
    "El uso de diferentes métricas no afectó la asignación de clusters. Esto puede deberse a que los datos tienen clusters bien definidos y la normalización minimizó diferencias entre distancias.\n",
    "\n",
    "Impacto de la Semilla de Inicialización\n",
    "El cambio de semilla no alteró los resultados, lo que sugiere que el algoritmo es robusto y converge a soluciones similares independientemente de la inicialización.\n",
    "\n",
    "Conclusión\n",
    "En este caso, ni la métrica de distancia ni la semilla de inicialización influyeron en la agrupación. Para futuros estudios, podría analizarse su efecto en datos más complejos o con ruido."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
